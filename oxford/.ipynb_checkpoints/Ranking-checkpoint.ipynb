{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import packages required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import pylab\n",
    "from collections import Counter\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import operator\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Fit a TfidfVectorizer and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_train = pd.read_csv('../data/merged_data/merged_train_textClean.csv', sep=',', header=0)\n",
    "Tfidf = TfidfVectorizer()\n",
    "Tfidf.fit(merged_train.body.tolist())\n",
    "pickle.dump(Tfidf, open(\"../data/merged_data/Tfidfvectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_emails_ids_per_sender(training):\n",
    "    sender_list = list(set(training.sender.tolist()))\n",
    "    emails_ids_per_sender = {}    \n",
    "    for s in sender_list:\n",
    "        emails_ids_per_sender[s] = [int(x) for x in training[training.sender==s]['mid'].tolist()]\n",
    "    return emails_ids_per_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rcy(t_new,t_m):\n",
    "    t_new = np.datetime64(t_new).astype('datetime64[D]')\n",
    "    t_m = np.datetime64(t_m).astype('datetime64[D]')\n",
    "    return round(((t_new - t_m).astype(float))**(-0.85),10)\n",
    "\n",
    "def cnt(c_new,c_m,Tfidf=TfidfVectorizer()):\n",
    "    c_new = Tfidf.transform([c_new]).toarray()\n",
    "    c_new = np.nan_to_num(c_new)\n",
    "    c_m = Tfidf.transform([c_m]).toarray()\n",
    "    c_m = np.nan_to_num(c_m)\n",
    "    return round(abs(1 - spatial.distance.cosine(c_new, c_m)),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rk(score_dic):\n",
    "    return {key: rank for rank, key in enumerate(sorted(score_dic, key=score_dic.get, reverse=True), 1)}\n",
    "\n",
    "def Rank_all(rank_r, rank_c, alpha=0.6):\n",
    "    rank = {}\n",
    "    for k in rank_r.iterkeys():\n",
    "        r_r = alpha/rank_r[k] if rank_r.get(k,0)!=0 else 0\n",
    "        r_c = (1-alpha)/rank_c[k] if rank_c.get(k,0)!=0 else 0\n",
    "        rank[k] = r_r + r_c\n",
    "    sorted_rank = [x[0] for x in sorted(rank.items(), key=operator.itemgetter(1),reverse=True)]        \n",
    "    return sorted_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CC_rank(new_mail,address_books,contact_books,df,Tfidf=TfidfVectorizer()): \n",
    "    \n",
    "    mid = new_mail[0]\n",
    "    sender = new_mail[1]\n",
    "    t_new = new_mail[2]\n",
    "    b_new = new_mail[3]\n",
    "    \n",
    "    G_recency = nx.DiGraph()\n",
    "    G_content = nx.DiGraph()\n",
    "    all_nodes = [sender] + address_books[sender]\n",
    "    edges = [(i,j) for i in all_nodes for j in all_nodes if all_nodes.index(j) > all_nodes.index(i)]\n",
    "    for edge in edges:\n",
    "        rcy_out = 0\n",
    "        rcy_in = 0\n",
    "        cnt_out = 0\n",
    "        cnt_in = 0\n",
    "        if contact_books.has_key(edge[0]) and contact_books[edge[0]].has_key(edge[1]):\n",
    "            dates = df[df.mid.isin(contact_books[edge[0]][edge[1]])]['date'].tolist()\n",
    "            for d in dates:\n",
    "                r_out = rcy(t_new,d)\n",
    "                rcy_out += 1 if math.isnan(r_out) or math.isinf(r_out) else r_out\n",
    "\n",
    "            bodies = df[df.mid.isin(contact_books[edge[0]][edge[1]])]['body'].tolist()\n",
    "            for b in bodies:\n",
    "                c_out = cnt(b_new,b,Tfidf=tfidf)\n",
    "                cnt_out += 1 if math.isnan(c_out) or math.isinf(c_out) else c_out\n",
    "\n",
    "        if contact_books.has_key(edge[1]) and contact_books[edge[1]].has_key(edge[0]):\n",
    "            dates = df[df.mid.isin(contact_books[edge[1]][edge[0]])]['date'].tolist()\n",
    "            for d in dates:\n",
    "                r_in = rcy(t_new,d)\n",
    "                rcy_in += 1 if math.isnan(r_in) or math.isinf(r_in) else r_in\n",
    "\n",
    "            bodies = df[df.mid.isin(contact_books[edge[1]][edge[0]])]['body'].tolist()\n",
    "            for b in bodies:\n",
    "                c_in = cnt(b_new,b,Tfidf=tfidf)\n",
    "                cnt_in += 1 if math.isnan(c_in) or math.isinf(c_in) else c_in\n",
    "\n",
    "        \n",
    "        \n",
    "        if rcy_out!=0:\n",
    "            G_recency.add_edge(edge[0],edge[1],weight=(6*rcy_out + rcy_in))\n",
    "            G_content.add_edge(edge[0],edge[1],weight=(6*cnt_out + cnt_in))\n",
    "            \n",
    "        if rcy_in!=0:\n",
    "            G_recency.add_edge(edge[1],edge[0],weight=(6*rcy_in + rcy_out))\n",
    "            G_content.add_edge(edge[1],edge[0],weight=(6*cnt_in + cnt_out))\n",
    "            \n",
    "            \n",
    "#         if (6*rcy_out + rcy_in)>0:\n",
    "#             G_recency.add_edge(edge[0],edge[1],weight=(6*rcy_out + rcy_in))\n",
    "#             G_recency.add_edge(edge[1],edge[0],weight=(6*rcy_in + rcy_out))\n",
    "#             if (6*cnt_out + cnt_in)>0:\n",
    "#                 G_content.add_edge(edge[0],edge[1],weight=(6*cnt_out + cnt_in))\n",
    "#                 G_content.add_edge(edge[1],edge[0],weight=(6*cnt_in + cnt_out))\n",
    "#             if (6*cnt_out + cnt_in)<=0:\n",
    "#                 G_content.add_edge(edge[0],edge[1],weight=0)\n",
    "#                 G_content.add_edge(edge[1],edge[0],weight=0)\n",
    "\n",
    "\n",
    "#         if (6*rcy_out + rcy_in)<0:\n",
    "#             G_recency.add_edge(edge[0],edge[1],weight=0)\n",
    "#             G_recency.add_edge(edge[1],edge[0],weight=0)\n",
    "            \n",
    "#         if (6*cnt_out + cnt_in)>0:\n",
    "#             G_content.add_edge(edge[0],edge[1],weight=(6*cnt_out + cnt_in))\n",
    "#             G_content.add_edge(edge[1],edge[0],weight=(6*cnt_in + cnt_out))\n",
    "#         if (6*cnt_out + cnt_in)<0:\n",
    "#             G_content.add_edge(edge[0],edge[1],weight=0)\n",
    "#             G_content.add_edge(edge[1],edge[0],weight=0)\n",
    "    \n",
    "#     nx.draw(G_recency)\n",
    "#     plt.show()\n",
    "    \n",
    "    rank_r = nx.algorithms.centrality.closeness_centrality(G_recency,distance='weight',normalized=True)\n",
    "    rank_r = rk(rank_r)\n",
    "    rank_c = nx.algorithms.centrality.closeness_centrality(G_content,distance='weight',normalized=True)\n",
    "    rank_c = rk(rank_c)\n",
    "    Rank = Rank_all(rank_r,rank_c)\n",
    "    if sender in Rank:\n",
    "        Rank.remove(sender)\n",
    "    return Rank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Rcy_rank(new_mail,address_books,contact_books,df):\n",
    "    mid = new_mail[0]\n",
    "    sender = new_mail[1]\n",
    "    t_new = new_mail[2]\n",
    "    b_new = new_mail[3]\n",
    "    \n",
    "    ran = {}\n",
    "\n",
    "    for rec in address_books[sender]:\n",
    "        score = 0\n",
    "        cache = df[df.mid.isin(contact_books[sender][rec])]['date'].tolist()\n",
    "        for d in cache:\n",
    "            r = rcy(t_new,d)\n",
    "            score += 1 if math.isnan(r) or math.isinf(r) else r\n",
    "            \n",
    "        ran[rec] = score\n",
    "#     sorted_rank = [x[0] for x in sorted(ran.items(), key=operator.itemgetter(1),reverse=True)]\n",
    "#     return sorted_rank[:10]\n",
    "    return rk(ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cnt_rank(new_mail,address_books,contact_books,df,Tfidf=TfidfVectorizer()):\n",
    "    mid = new_mail[0]\n",
    "    sender = new_mail[1]\n",
    "    t_new = new_mail[2]\n",
    "    b_new = Tfidf.transform([new_mail[3]]).toarray()\n",
    "#     print b_new.shape\n",
    "    ran = {}\n",
    "    \n",
    "    for rec in address_books[sender]:\n",
    "        score = 0\n",
    "        cache = df[df.mid.isin(contact_books[sender][rec])]['body'].tolist()\n",
    "        a_m = Tfidf.transform(cache).toarray()\n",
    "        for row in a_m:\n",
    "#             print row.shape\n",
    "            score += abs(spatial.distance.cosine(b_new, row))\n",
    "\n",
    "        ran[rec] = score\n",
    "    return rk(ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = pickle.load(open(\"../data/merged_data/Tfidfvectorizer.pickle\", \"rb\"))\n",
    "\n",
    "test = pd.read_csv('../data/merged_data/eva_test.csv', sep=',', header=0)\n",
    "train = pd.read_csv('../data/merged_data/eva_train.csv', sep=',', header=0)\n",
    "\n",
    "emails_ids_per_sender = get_emails_ids_per_sender(train)\n",
    "all_senders = emails_ids_per_sender.keys()\n",
    "\n",
    "address_books = {}\n",
    "for sender in all_senders:\n",
    "    book = train[train.sender==sender]['recipients'].tolist()\n",
    "    book = [x for subitem in book for x in subitem.split(\" \")]\n",
    "    book = list(set(book))\n",
    "    address_books[sender] = book\n",
    "\n",
    "contact_books = {}\n",
    "for sender in all_senders:\n",
    "    mails = train[train.sender==sender]\n",
    "    book = {}\n",
    "    for rec in address_books[sender]:\n",
    "        rec_mail =mails[mails.recipients.str.contains(rec)]['mid'].tolist()\n",
    "        book[rec] = rec_mail\n",
    "    contact_books[sender] = book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/Python2.7/lib/python2.7/site-packages/ipykernel/__main__.py:4: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "with open(\"../results/networkx_result_v0.1.txt\", 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    i = 0\n",
    "    for index,serie in test.iterrows():\n",
    "        row = serie.tolist()\n",
    "        mid = str(row[0])\n",
    "        rank = CC_rank(row,address_books,contact_books,train,Tfidf=tfidf)\n",
    "        my_file.write(mid + ',' + ' '.join(rank) + '\\n')\n",
    "\n",
    "        i += 1\n",
    "        if i%50==0:\n",
    "            print i\n",
    "        \n",
    "    my_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../results/Cnt_result_v0.1.txt\", 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    i = 0\n",
    "    for index,serie in test.iterrows():\n",
    "        row = serie.tolist()\n",
    "        mid = str(row[0])\n",
    "#         d1 = Rcy_rank(row,address_books,contact_books,train)\n",
    "        d2 = Cnt_rank(row,address_books,contact_books,train,Tfidf=tfidf)\n",
    "#         rn = Rank_all(d1,d2)[:10]\n",
    "        rn = [x[0] for x in sorted(d2.items(), key=operator.itemgetter(1),reverse=True)]\n",
    "        my_file.write(mid + ',' + ' '.join(rn[:10]) + '\\n')\n",
    "\n",
    "        i += 1\n",
    "        if i%50==0:\n",
    "            print i\n",
    "        \n",
    "    my_file.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Python2.7]",
   "language": "python",
   "name": "conda-env-Python2.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
